{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from config.config import PRODUCER_CONFIG\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "import json\n",
    "\n",
    "KAFKA_TOPIC = PRODUCER_CONFIG['KAFKA_TOPIC']\n",
    "BOOTSTRAP_SERVER = \"localhost:9092\"\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc,2) #stream each one second\n",
    "ssc.checkpoint(\"./checkpoint\")\n",
    "data = KafkaUtils.createDirectStream(ssc, [KAFKA_TOPIC],\n",
    "                                  {\"metadata.broker.list\": BOOTSTRAP_SERVER})\n",
    "def updateFunc(newVal, oldVal):  \n",
    "    if oldVal is None:\n",
    "        oldVal=([], [], [])\n",
    "    old_id, old_desc, old_publish = oldVal\n",
    "    new_id = [x[0] for x in newVal]\n",
    "    new_desc = [x[1] for x in newVal]\n",
    "    new_publish = [x[2] for x in newVal]\n",
    "    return (old_id+new_id, old_desc+new_desc, old_publish+new_publish)\n",
    "def saveToParquet(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        df=rdd.toDF()\n",
    "        df.write.format(\"parquet\").mode('append').save(PRODUCER_CONFIG['HDFS_FOLDER'])\n",
    "def prepare_rdd(data, window_length=2, sliding_interval=2):\n",
    "    data = data.window(window_length, sliding_interval).map(lambda x:json.loads(x[1]))\n",
    "    data = data.map(\n",
    "         lambda x: (x['video_id'], x['description'], x['published_at'], x['channel_title'], x['video_title'])\n",
    "    )\n",
    "    data.foreachRDD(saveToParquet)\n",
    "    return data\n",
    "# run the function\n",
    "result = prepare_rdd(data)\n",
    "# Print\n",
    "result.pprint()\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
